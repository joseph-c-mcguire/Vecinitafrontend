# Vecinita - RAG Chatbot Simplificado

Asistente de informaci√≥n ambiental y comunitaria biling√ºe (Espa√±ol/Ingl√©s) con soporte completo de accesibilidad.

## Caracter√≠sticas

### ‚ú® Funcionalidad Principal
- **Chatbot RAG** con atribuci√≥n de fuentes y citaciones
- **Biling√ºe** (Espa√±ol/Ingl√©s) con selector de idioma
- **Idioma predeterminado**: Espa√±ol
- **Sistema de retroalimentaci√≥n** para respuestas del chat (üëç/üëé con comentarios opcionales)
- Respuestas simuladas con fuentes citadas (listo para integraci√≥n con backend real)

### üé® Dise√±o
- **Tema personalizable**: Modo claro/oscuro con persistencia
- **Colores**: Esquema de colores VECINA con turquesa primario (#4DB8B8)
- Interfaz moderna y limpia
- Completamente responsivo

### ‚ôø Accesibilidad
- **Ajuste de tama√±o de fuente**: Peque√±o, Mediano, Grande, Extra Grande
- **Modo de alto contraste**: Para mejor visibilidad
- **Reducci√≥n de movimiento**: Minimiza animaciones
- Navegaci√≥n completa por teclado
- Etiquetas ARIA y roles sem√°nticos
- Enlace "Saltar al contenido principal"

### ‚öôÔ∏è Configuraci√≥n del Backend
- Selecci√≥n de **modelo LLM** (GPT-4, Claude, etc.)
- Selecci√≥n de **servicio de embeddings** (OpenAI, Cohere, HuggingFace, Voyage AI)
- Configuraciones persistentes en localStorage

### ‚å®Ô∏è Atajos de Teclado
- `Alt + N`: Nueva conversaci√≥n
- `Alt + S`: Abrir configuraci√≥n del backend
- `Alt + A`: Abrir panel de accesibilidad
- `Alt + K`: Mostrar atajos de teclado
- `Alt + /`: Enfocar entrada de mensaje
- `Enter`: Enviar mensaje
- `Shift + Enter`: Nueva l√≠nea
- `Escape`: Cerrar modal/panel
- `Tab / Shift + Tab`: Navegaci√≥n

## Lo que NO est√° incluido

Esta versi√≥n simplificada **no incluye**:
- ‚ùå Sistema de autenticaci√≥n/login
- ‚ùå Historial de conversaciones persistente
- ‚ùå Integraci√≥n con base de datos
- ‚ùå Panel de administrador
- ‚ùå Gesti√≥n de usuarios

Todas las preferencias del usuario (tema, idioma, accesibilidad, configuraci√≥n del backend) se almacenan localmente en `localStorage`. La retroalimentaci√≥n de mensajes tambi√©n se guarda en `localStorage`.

## üìö Documentaci√≥n

Para m√°s informaci√≥n, consulta nuestros [documentos completos](./docs/INDEX.md):

- **[QUICK_START.md](./docs/guides/QUICK_START.md)** - Gu√≠a r√°pida para usuarios finales
- **[CHATWIDGET_README.md](./docs/reference/CHATWIDGET_README.md)** - Integraci√≥n del componente ChatWidget
- **[CONTRIBUTING.md](./docs/guides/CONTRIBUTING.md)** - Gu√≠a de desarrollo
- **[docs/INDEX.md](./docs/INDEX.md)** - √çndice completo de documentaci√≥n

Para informaci√≥n sobre accesibilidad, consulta [docs/es/ACCESIBILIDAD.md](./docs/es/ACCESIBILIDAD.md).

## Tecnolog√≠as

- **React 18** con TypeScript
- **Tailwind CSS v4** para estilos
- **Lucide React** para iconos
- **Radix UI** para componentes accesibles
- **Vite** para desarrollo y compilaci√≥n

## Integraci√≥n Futura del Backend

Esta aplicaci√≥n est√° lista para conectarse a un backend RAG. La funci√≥n `getMockResponse` en `/src/app/App.tsx` debe ser reemplazada con:

1. **Generaci√≥n de embeddings** para la consulta del usuario
2. **B√∫squeda vectorial** en base de datos Supabase
3. **Construcci√≥n de contexto** a partir de documentos coincidentes
4. **Llamada al LLM** con contexto y consulta
5. **Retorno de respuesta** con fuentes citadas

### Ejemplo de integraci√≥n:

```typescript
const getRagResponse = async (userMessage: string) => {
  // 1. Generar embedding para la consulta
  const queryEmbedding = await generateQueryEmbedding(userMessage, {
    provider: settings.embeddingProvider,
    model: settings.embeddingModel
  });
  
  // 2. Buscar documentos relevantes en vector database
  const { data: matches } = await supabase.rpc('match_documents', {
    query_embedding: queryEmbedding,
    match_threshold: 0.7,
    match_count: 5
  });
  
  // 3. Construir contexto
  const context = matches.map(m => m.content).join('\n\n');
  
  // 4. Llamar al LLM
  const llmResponse = await callLLM({
    model: settings.llmModel,
    provider: settings.llmProvider,
    context,
    query: userMessage,
    language: language
  });
  
  // 5. Construir array de fuentes
  const sources = matches.map(m => ({
    title: m.metadata.title,
    url: m.metadata.url,
    snippet: m.content.substring(0, 200)
  }));
  
  return { content: llmResponse, sources };
};
```

## Instalaci√≥n y Desarrollo

```bash
# Instalar dependencias (autom√°tico en Figma Make)
npm install

# Ejecutar en modo desarrollo
npm run dev

# Compilar para producci√≥n
npm run build
```

## Estructura del Proyecto

```
/src
  /app
    /components        # Componentes React
      ChatMessage.tsx       # Componente de mensaje con fuentes
      MessageFeedback.tsx   # Sistema de retroalimentaci√≥n
      SourceCard.tsx        # Tarjeta de fuente citada
      ThemeToggle.tsx       # Selector de tema
      LanguageSelector.tsx  # Selector de idioma
      AccessibilityPanel.tsx # Panel de opciones de accesibilidad
      BackendSettingsPanel.tsx # Configuraci√≥n de modelos
      KeyboardShortcutsHelp.tsx # Ayuda de atajos
      SkipToContent.tsx     # Enlace de accesibilidad
    /context           # Contextos React
      LanguageContext.tsx      # Estado de idioma
      AccessibilityContext.tsx # Estado de accesibilidad
      BackendSettingsContext.tsx # Configuraci√≥n del backend
    /services          # L√≥gica de negocio
      modelRegistry.ts  # Registro de modelos LLM/embedding
    App.tsx           # Componente principal
  /styles
    theme.css         # Variables de tema y CSS personalizado
    tailwind.css      # Configuraci√≥n Tailwind
```

## Almacenamiento Local

La aplicaci√≥n utiliza `localStorage` para persistir:

- `vecinita-theme`: Preferencia de tema (light/dark)
- `accessibility-settings`: Configuraci√≥n de accesibilidad
- `vecinita-backend-settings`: Configuraci√≥n de modelos LLM/embedding
- `vecinita_message_feedback`: Retroalimentaci√≥n de mensajes

## Personalizaci√≥n

### Colores
Los colores principales se definen en `/src/styles/theme.css`:
- Primary: `#4DB8B8` (turquoise de VECINA)
- Los colores se ajustan autom√°ticamente para modo oscuro y alto contraste

### Traducciones
Las traducciones se gestionan en `/src/app/context/LanguageContext.tsx`. Para agregar nuevas traducciones:

```typescript
newKey: {
  en: 'English text',
  es: 'Texto en espa√±ol',
}
```

### Modelos
Los modelos LLM y de embeddings disponibles se definen en `/src/app/services/modelRegistry.ts`.

## Licencia

Este proyecto fue creado para proporcionar informaci√≥n ambiental y comunitaria. Vecinita proporciona informaci√≥n general - siempre verifica con fuentes oficiales.
